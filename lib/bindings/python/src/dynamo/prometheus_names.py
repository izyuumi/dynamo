# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

"""
Python constants for Prometheus metric names

AUTO-GENERATED from lib/runtime/src/metrics/prometheus_names.rs
DO NOT EDIT THIS FILE MANUALLY

To regenerate this file after modifying lib/runtime/src/metrics/prometheus_names.rs:
    cargo run -p dynamo-codegen --bin gen-python-prometheus-names

This module provides pure Python access to Prometheus metric name constants
without requiring Rust bindings.

Usage (both patterns supported):
    # Pattern 1: Import module
    from dynamo import prometheus_names
    print(prometheus_names.frontend_service.REQUESTS_TOTAL)  # "requests_total"
    print(prometheus_names.kvstats.ACTIVE_BLOCKS)  # "kvstats_active_blocks"

    # Pattern 2: Import specific classes
    from dynamo.prometheus_names import frontend_service, kvstats
    print(frontend_service.REQUESTS_TOTAL)  # "requests_total"
    print(kvstats.ACTIVE_BLOCKS)  # "kvstats_active_blocks"
"""

from __future__ import annotations


class distributed_runtime:
    """DistributedRuntime core metrics"""

    # Total uptime of the DistributedRuntime in seconds
    UPTIME_SECONDS = "uptime_seconds"


class frontend_service:
    """Frontend service metrics (LLM HTTP service)"""

    # Environment variable that overrides the default metric prefix
    METRICS_PREFIX_ENV = "DYN_METRICS_PREFIX"
    # Total number of LLM requests processed
    REQUESTS_TOTAL = "requests_total"
    # Number of requests waiting in HTTP queue before receiving the first response (gauge)
    QUEUED_REQUESTS = "queued_requests"
    # Number of inflight/concurrent requests going to the engine (vLLM, SGLang, ...)
    # Note: This is a gauge metric (current state) that can go up and down, so no _total suffix
    INFLIGHT_REQUESTS = "inflight_requests"
    # Number of disconnected clients (gauge that can go up and down)
    DISCONNECTED_CLIENTS = "disconnected_clients"
    # Duration of LLM requests
    REQUEST_DURATION_SECONDS = "request_duration_seconds"
    # Input sequence length in tokens
    INPUT_SEQUENCE_TOKENS = "input_sequence_tokens"
    # Output sequence length in tokens
    OUTPUT_SEQUENCE_TOKENS = "output_sequence_tokens"
    # Time to first token in seconds
    TIME_TO_FIRST_TOKEN_SECONDS = "time_to_first_token_seconds"
    # Inter-token latency in seconds
    INTER_TOKEN_LATENCY_SECONDS = "inter_token_latency_seconds"
    # Model configuration metrics
    # Runtime config metrics (from ModelRuntimeConfig):
    # Total KV blocks available for a worker serving the model
    MODEL_TOTAL_KV_BLOCKS = "model_total_kv_blocks"
    # Maximum number of sequences for a worker serving the model (runtime config)
    MODEL_MAX_NUM_SEQS = "model_max_num_seqs"
    # Maximum number of batched tokens for a worker serving the model (runtime config)
    MODEL_MAX_NUM_BATCHED_TOKENS = "model_max_num_batched_tokens"
    # MDC metrics (from ModelDeploymentCard):
    # Maximum context length for a worker serving the model (MDC)
    MODEL_CONTEXT_LENGTH = "model_context_length"
    # KV cache block size for a worker serving the model (MDC)
    MODEL_KV_CACHE_BLOCK_SIZE = "model_kv_cache_block_size"
    # Request migration limit for a worker serving the model (MDC)
    MODEL_MIGRATION_LIMIT = "model_migration_limit"


class kvbm_connector:
    """KVBM connector"""

    # KVBM connector leader
    KVBM_CONNECTOR_LEADER = "kvbm_connector_leader"
    # KVBM connector worker
    KVBM_CONNECTOR_WORKER = "kvbm_connector_worker"


class kvrouter:
    # Number of KV cache events applied to the index (including status)
    KV_CACHE_EVENTS_APPLIED = "kv_cache_events_applied"


class kvstats:
    """KvStats metrics from LLM workers"""

    # Prefix for all KvStats metrics
    PREFIX = ""
    # Number of active KV cache blocks currently in use
    ACTIVE_BLOCKS = "kvstats_active_blocks"
    # Total number of KV cache blocks available
    TOTAL_BLOCKS = "kvstats_total_blocks"
    # GPU cache usage as a percentage (0.0-1.0)
    GPU_CACHE_USAGE_PERCENT = "kvstats_gpu_cache_usage_percent"
    # GPU prefix cache hit rate as a percentage (0.0-1.0)
    GPU_PREFIX_CACHE_HIT_RATE = "kvstats_gpu_prefix_cache_hit_rate"


class labels:
    """Automatically inserted Prometheus label names used across the metrics system"""

    # Label for component identification
    COMPONENT = "dynamo_component"
    # Label for namespace identification
    NAMESPACE = "dynamo_namespace"
    # Label for endpoint identification
    ENDPOINT = "dynamo_endpoint"


class name_prefix:
    """Metric name prefixes used across the metrics system"""

    # Prefix for all Prometheus metric names.
    COMPONENT = "dynamo_component"
    # Prefix for frontend service metrics
    FRONTEND = "dynamo_frontend"


class nats_client:
    """NATS client metrics. DistributedRuntime contains a NATS client shared by all children)"""

    # Prefix for all NATS client metrics
    PREFIX = ""
    # Total number of bytes received by NATS client
    IN_TOTAL_BYTES = "nats_client_in_total_bytes"
    # Total number of bytes sent by NATS client
    OUT_OVERHEAD_BYTES = "nats_client_out_overhead_bytes"
    # Total number of messages received by NATS client
    IN_MESSAGES = "nats_client_in_messages"
    # Total number of messages sent by NATS client
    OUT_MESSAGES = "nats_client_out_messages"
    # Current number of active connections for NATS client
    # Note: Gauge metric measuring current connections, not cumulative total
    CURRENT_CONNECTIONS = "nats_client_current_connections"
    # Current connection state of NATS client (0=disconnected, 1=connected, 2=reconnecting)
    CONNECTION_STATE = "nats_client_connection_state"


class nats_service:
    """NATS service metrics, from the $SRV.STATS.<service_name> requests on NATS server"""

    # Prefix for all NATS service metrics
    PREFIX = ""
    # Average processing time in milliseconds (maps to: average_processing_time in ms)
    PROCESSING_MS_AVG = "nats_service_processing_ms_avg"
    # Total errors across all endpoints (maps to: num_errors)
    ERRORS_TOTAL = "nats_service_errors_total"
    # Total requests across all endpoints (maps to: num_requests)
    REQUESTS_TOTAL = "nats_service_requests_total"
    # Total processing time in milliseconds (maps to: processing_time in ms)
    PROCESSING_MS_TOTAL = "nats_service_processing_ms_total"
    # Number of active services (derived from ServiceSet.services)
    ACTIVE_SERVICES = "nats_service_active_services"
    # Number of active endpoints (derived from ServiceInfo.endpoints)
    ACTIVE_ENDPOINTS = "nats_service_active_endpoints"


class task_tracker:
    """Task tracker Prometheus metric name suffixes"""

    # Total number of tasks issued/submitted
    TASKS_ISSUED_TOTAL = "tasks_issued_total"
    # Total number of tasks started
    TASKS_STARTED_TOTAL = "tasks_started_total"
    # Total number of successfully completed tasks
    TASKS_SUCCESS_TOTAL = "tasks_success_total"
    # Total number of cancelled tasks
    TASKS_CANCELLED_TOTAL = "tasks_cancelled_total"
    # Total number of failed tasks
    TASKS_FAILED_TOTAL = "tasks_failed_total"
    # Total number of rejected tasks
    TASKS_REJECTED_TOTAL = "tasks_rejected_total"


class work_handler:
    """Work handler Prometheus metric names"""

    # Total number of requests processed by work handler
    REQUESTS_TOTAL = "requests_total"
    # Total number of bytes received in requests by work handler
    REQUEST_BYTES_TOTAL = "request_bytes_total"
    # Total number of bytes sent in responses by work handler
    RESPONSE_BYTES_TOTAL = "response_bytes_total"
    # Number of requests currently being processed by work handler
    # Note: This is a gauge metric (current state) that can go up and down, so no _total suffix
    INFLIGHT_REQUESTS = "inflight_requests"
    # Time spent processing requests by work handler (histogram)
    REQUEST_DURATION_SECONDS = "request_duration_seconds"
    # Total number of errors in work handler processing
    ERRORS_TOTAL = "errors_total"
    # Label name for error type classification
    ERROR_TYPE_LABEL = "error_type"
