name: 'Docker Build'
description: 'Build Dynamo container images'
inputs:
  framework:
    description: 'Framework to build'
    required: true
    default: 'vllm'
  target:
    description: 'Target to build'
    required: false
    default: 'runtime'
  platform:
    description: 'Docker platform to build on, ie. linux/amd64'
    required: false
    default: 'linux/amd64'
  image_tag:
    description: 'Custom image tag (optional, defaults to framework:latest)'
    required: false
  ngc_ci_access_token:
    description: 'NGC CI Access Token'
    required: false
  ci_token:
    description: 'CI Token'
    required: false
  aws_default_region:
    description: 'AWS Default Region'
    required: false
  sccache_s3_bucket:
    description: 'SCCache S3 Bucket'
    required: false
  aws_access_key_id:
    description: 'AWS Access Key ID'
    required: false
  aws_secret_access_key:
    description: 'AWS Secret Access Key'
    required: false

outputs:
  image_tag:
    description: 'Image Tag'
    value: ${{ steps.build.outputs.image_tag }}
  # Timing outputs
  build-start-time:
    description: 'Build start time'
    value: ${{ steps.setup.outputs.build-start-time }}
  build-end-time:
    description: 'Build end time'
    value: ${{ steps.metrics.outputs.build-end-time }}
  build-duration-sec:
    description: 'Build duration in seconds'
    value: ${{ steps.metrics.outputs.build-duration-sec }}
  # Metrics outputs
  image-size-bytes:
    description: 'Image size in bytes'
    value: ${{ steps.metrics.outputs.image-size-bytes }}
  framework:
    description: 'Framework name'
    value: ${{ steps.metrics.outputs.framework }}
  target:
    description: 'Build target'
    value: ${{ steps.metrics.outputs.target }}
  platform-arch:
    description: 'Platform architecture (amd64/arm64)'
    value: ${{ steps.metrics.outputs.platform-arch }}

runs:
  using: "composite"
  steps:
    - name: Setup Build Environment and Capture Start Time
      id: setup
      shell: bash
      run: |
        # Capture build start time
        BUILD_START_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)
        echo "ðŸ• Build started at: ${BUILD_START_TIME}"
        echo "BUILD_START_TIME=${BUILD_START_TIME}" >> $GITHUB_ENV
        echo "build-start-time=${BUILD_START_TIME}" >> $GITHUB_OUTPUT
        
        echo "ðŸ”§ Setting up build environment for ${{ inputs.framework }}..."
        
        # Add setup commands here if needed
        # Setup sccache
        # curl -L https://github.com/mozilla/sccache/releases/download/v0.7.4/sccache-v0.7.4-x86_64-unknown-linux-musl.tar.gz | tar xz
        # sudo mv sccache-*/sccache /usr/local/bin/sccache
        # sccache --start-server
        
        echo "âœ… Build environment setup complete"

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 #v3.11.1
      with:
        # This is not # of CPUs, this is CPU priority, 1024 is the default
        driver-opts: 'cpu-shares=100'
    - name: Login to NGC
      if: github.event.pull_request.head.repo.full_name == github.repository || github.event_name == 'push'
      shell: bash
      run: |
        echo "${{ inputs.ngc_ci_access_token }}" | docker login nvcr.io -u '$oauthtoken' --password-stdin
    - name: Cleanup
      if: always()
      shell: bash
      run: |
        docker system prune -af
    - name: Build image
      id: build
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.ci_token }}
        AWS_DEFAULT_REGION: ${{ inputs.aws_default_region }}
        SCCACHE_S3_BUCKET:  ${{ inputs.sccache_s3_bucket }}
        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        PLATFORM: ${{ inputs.platform }}
      run: |
        # Determine image tag
        if [ -n "${{ inputs.image_tag }}" ]; then
          IMAGE_TAG="${{ inputs.image_tag }}"
        else
          IMAGE_TAG="${{ inputs.framework }}:latest"
        fi

        echo "image_tag=$IMAGE_TAG" >> $GITHUB_OUTPUT
        ./container/build.sh --tag "$IMAGE_TAG" \
          --target ${{ inputs.target }} \
          --vllm-max-jobs 10 \
          --framework ${{ inputs.framework }} \
          --platform ${{ inputs.platform }} \
          --use-sccache \
          --sccache-bucket "$SCCACHE_S3_BUCKET" \
          --sccache-region "$AWS_DEFAULT_REGION"

    - name: Capture Build Metrics
      id: metrics
      shell: bash
      run: |
        echo "ðŸ“Š Capturing build metrics for ${{ inputs.framework }}..."
        
        # Create metrics directory
        mkdir -p build-metrics
        
        # Get accurate build timing
        BUILD_START_TIME="${{ env.BUILD_START_TIME }}"
        BUILD_END_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)
        
        # Calculate duration
        START_EPOCH=$(date -d "$BUILD_START_TIME" +%s)
        END_EPOCH=$(date -d "$BUILD_END_TIME" +%s)
        BUILD_DURATION_SEC=$((END_EPOCH - START_EPOCH))
        
        echo "ðŸ• Build timing:"
        echo "  Start: ${BUILD_START_TIME}"
        echo "  End: ${BUILD_END_TIME}"
        echo "  Duration: ${BUILD_DURATION_SEC} seconds"
        
        # Get image size using docker inspect
        IMAGE_TAG="${{ steps.build.outputs.image_tag }}"
        if [ -n "$IMAGE_TAG" ]; then
          IMAGE_SIZE_BYTES=$(docker image inspect "$IMAGE_TAG" --format='{{.Size}}' 2>/dev/null || echo "0")
          echo "ðŸ“¦ Image size: ${IMAGE_SIZE_BYTES} bytes"
        else
          IMAGE_SIZE_BYTES=0
          echo "âš ï¸  No image tag available"
        fi
        
        echo "ðŸ“Š Final metrics captured"
        
        # Create consolidated metrics JSON file
        PLATFORM_ARCH=$(echo "${{ inputs.platform }}" | sed 's/linux\///')
        JOB_KEY="${{ inputs.framework }}-${PLATFORM_ARCH}"
        
        # Create or update consolidated metrics file
        METRICS_FILE="build-metrics/consolidated-metrics.json"
        
        # Create base structure if file doesn't exist
        if [ ! -f "$METRICS_FILE" ]; then
          echo '{}' > "$METRICS_FILE"
        fi
        
        # Use jq to add this job's metrics to the consolidated file
        # First create the job metrics as a temporary file
        cat > /tmp/job_metrics.json << EOF
        {
          "framework": "${{ inputs.framework }}",
          "target": "${{ inputs.target }}",
          "platform": "${{ inputs.platform }}",
          "platform_arch": "${PLATFORM_ARCH}",
          "image_size_bytes": ${IMAGE_SIZE_BYTES},
          "build_start_time": "${BUILD_START_TIME}",
          "build_end_time": "${BUILD_END_TIME}",
          "build_duration_sec": ${BUILD_DURATION_SEC}
        }
        EOF
        
        # Install jq if not available (lightweight JSON processor)
        if ! command -v jq &> /dev/null; then
          echo "ðŸ“¦ Installing jq for JSON processing..."
          sudo apt-get update -qq && sudo apt-get install -y jq
        fi
        
        # Add job metrics to consolidated file with proper locking
        (
          flock -x 200
          jq --argjson job_metrics "$(cat /tmp/job_metrics.json)" \
             --arg job_key "$JOB_KEY" \
             '.[$job_key] = $job_metrics' "$METRICS_FILE" > /tmp/updated_metrics.json
          mv /tmp/updated_metrics.json "$METRICS_FILE"
        ) 200>/tmp/metrics_lock
        
        echo "ðŸ“ Updated consolidated build metrics for ${JOB_KEY}:"
        jq ".\"$JOB_KEY\"" "$METRICS_FILE"
        
        # Clean up temp file
        rm -f /tmp/job_metrics.json
        
        # Set outputs
        echo "build-end-time=${BUILD_END_TIME}" >> $GITHUB_OUTPUT
        echo "build-duration-sec=${BUILD_DURATION_SEC}" >> $GITHUB_OUTPUT
        echo "image-size-bytes=${IMAGE_SIZE_BYTES}" >> $GITHUB_OUTPUT
        echo "framework=${{ inputs.framework }}" >> $GITHUB_OUTPUT
        echo "target=${{ inputs.target }}" >> $GITHUB_OUTPUT
        echo "platform-arch=${PLATFORM_ARCH}" >> $GITHUB_OUTPUT

    # Upload consolidated build metrics as artifact
    - name: Upload Build Metrics
      uses: actions/upload-artifact@v4
      with:
        name: build-metrics-consolidated
        path: build-metrics/consolidated-metrics.json
        retention-days: 7
